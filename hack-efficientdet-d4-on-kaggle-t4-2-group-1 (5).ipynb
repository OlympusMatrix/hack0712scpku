{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":105557,"databundleVersionId":13020096,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# EfficientDet-D4 on Kaggle T4×2 (Group 1)\n\n# Cell 0: 环境检查 & 依赖安装\nimport torch; print(\"CUDA:\", torch.cuda.is_available(), \"GPUs:\", torch.cuda.device_count())\n!pip install effdet pycocotools albumentations scikit-learn matplotlib tqdm\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-12T15:40:00.056684Z","iopub.execute_input":"2025-07-12T15:40:00.057020Z","iopub.status.idle":"2025-07-12T15:40:03.423493Z","shell.execute_reply.started":"2025-07-12T15:40:00.056989Z","shell.execute_reply":"2025-07-12T15:40:03.422764Z"}},"outputs":[{"name":"stdout","text":"CUDA: True GPUs: 2\nRequirement already satisfied: effdet in /usr/local/lib/python3.11/dist-packages (0.4.1)\nRequirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (2.0.10)\nRequirement already satisfied: albumentations in /usr/local/lib/python3.11/dist-packages (2.0.8)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\nRequirement already satisfied: torch>=1.12.1 in /usr/local/lib/python3.11/dist-packages (from effdet) (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from effdet) (0.21.0+cu124)\nRequirement already satisfied: timm>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from effdet) (1.0.15)\nRequirement already satisfied: omegaconf>=2.0 in /usr/local/lib/python3.11/dist-packages (from effdet) (2.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pycocotools) (1.26.4)\nRequirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from albumentations) (1.15.3)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from albumentations) (6.0.2)\nRequirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.11/dist-packages (from albumentations) (2.11.7)\nRequirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.11/dist-packages (from albumentations) (0.0.24)\nRequirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albumentations) (4.11.0.86)\nRequirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations) (3.12.5)\nRequirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations) (6.4.9)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->pycocotools) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->pycocotools) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->pycocotools) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->pycocotools) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->pycocotools) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->pycocotools) (2.4.1)\nRequirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf>=2.0->effdet) (4.9.3)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (2.33.2)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (4.14.0)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (0.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm>=0.9.2->effdet) (0.33.1)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm>=0.9.2->effdet) (0.5.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.1->effdet) (3.18.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.1->effdet) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.1->effdet) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.1->effdet) (2025.5.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.1->effdet) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.1->effdet) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.1->effdet) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.1->effdet) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.1->effdet) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.1->effdet) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.1->effdet) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.1->effdet) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.1->effdet) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.1->effdet) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.1->effdet) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.1->effdet) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.1->effdet) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.1->effdet) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.1->effdet) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.12.1->effdet) (1.3.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm>=0.9.2->effdet) (2.32.4)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm>=0.9.2->effdet) (1.1.5)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.12.1->effdet) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->pycocotools) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->pycocotools) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->pycocotools) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->pycocotools) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->pycocotools) (2024.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm>=0.9.2->effdet) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm>=0.9.2->effdet) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm>=0.9.2->effdet) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm>=0.9.2->effdet) (2025.6.15)\n","output_type":"stream"}],"execution_count":110},{"cell_type":"code","source":"# Cell 1: 导入常用库 & 处理 Mixup 导入\nimport os, glob, math, json\nimport torch\nimport numpy as np\nimport pandas as pd\nimport albumentations as A\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\nfrom effdet import get_efficientdet_config, create_model, DetBenchTrain, DetBenchPredict\n# 尝试导入 Mixup\ntry:\n    from effdet.data.transforms import Mixup\n    mixup_fn = Mixup(mixup_alpha=1.0, prob=0.5, num_classes=9)\n    print(\"✅ Mixup enabled\")\nexcept ImportError:\n    Mixup = None\n    mixup_fn = None\n    print(\"⚠️ Mixup not available, skipping\")\nfrom torchvision.ops import nms\nfrom tqdm.auto import tqdm\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-12T15:40:03.425468Z","iopub.execute_input":"2025-07-12T15:40:03.426236Z","iopub.status.idle":"2025-07-12T15:40:03.432835Z","shell.execute_reply.started":"2025-07-12T15:40:03.426199Z","shell.execute_reply":"2025-07-12T15:40:03.432189Z"}},"outputs":[{"name":"stdout","text":"⚠️ Mixup not available, skipping\n","output_type":"stream"}],"execution_count":111},{"cell_type":"code","source":"# Cell 2: 数据统计（验证不平衡）\nlabel_files = glob.glob('/kaggle/input/**/train/labels/*.txt', recursive=True)\ncounts = {i:0 for i in range(9)}\nfor lf in label_files:\n    with open(lf) as f:\n        for line in f:\n            cls = int(line.split()[0])\n            counts[cls] += 1\ndf = pd.DataFrame({\n    'class_id': list(counts.keys()),\n    'count': list(counts.values())\n})\nprint(\"Train distribution:\\n\", df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-12T15:40:03.433653Z","iopub.execute_input":"2025-07-12T15:40:03.433851Z","iopub.status.idle":"2025-07-12T15:40:05.427657Z","shell.execute_reply.started":"2025-07-12T15:40:03.433834Z","shell.execute_reply":"2025-07-12T15:40:05.426727Z"}},"outputs":[{"name":"stdout","text":"Train distribution:\n    class_id  count\n0         0    123\n1         1     71\n2         2    640\n3         3    159\n4         4    141\n5         5    266\n6         6    127\n7         7   3169\n8         8   1610\n","output_type":"stream"}],"execution_count":112},{"cell_type":"code","source":"# Cell 3: Dataset + Augmentations + Sampler —— 最终可跑版\n\nimport glob, numpy as np, torch, matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\nimport albumentations as A\n\n# 1. 固定输入尺寸\nIMG_SIZE = 1024\n\n# 2. Dataset\nclass TrafficDataset(Dataset):\n    def __init__(self, root, split='train', transforms=None):\n        self.img_paths = sorted(glob.glob(f\"{root}/{split}/images/*.jpg\"))\n        self.label_paths = [\n            p.replace(f\"/{split}/images/\", f\"/{split}/labels/\").replace('.jpg', '.txt')\n            for p in self.img_paths\n        ]\n        self.transforms = transforms\n\n    def __len__(self):\n        return len(self.img_paths)\n\n    def __getitem__(self, idx):\n        img = plt.imread(self.img_paths[idx])\n        h, w = img.shape[:2]\n\n        # 读取 YOLO 标签\n        boxes, labels = [], []\n        with open(self.label_paths[idx]) as f:\n            for line in f:\n                if not line.strip():\n                    continue\n                c, xc, yc, bw, bh = map(float, line.split())\n                x1 = (xc - bw / 2) * w\n                y1 = (yc - bh / 2) * h\n                boxes.append([x1, y1, bw * w, bh * h])\n                labels.append(int(c))\n        boxes  = np.array(boxes)  if boxes  else np.zeros((0, 4))\n        labels = np.array(labels) if labels else np.zeros((0,), dtype=int)\n\n        # Albumentations Resize + Aug\n        if self.transforms:\n            aug = self.transforms(image=img, bboxes=boxes, category_id=labels)\n            img, boxes, labels = aug['image'], np.array(aug['bboxes']), np.array(aug['category_id'])\n\n        # 转 Tensor\n        img_t    = torch.tensor(img).permute(2, 0, 1).float() / 255.0\n        boxes_t  = torch.tensor(boxes,  dtype=torch.float32)\n        labels_t = torch.tensor(labels, dtype=torch.int64)\n        num_pos  = torch.tensor([labels_t.size(0)], dtype=torch.int64)\n\n        target = {\n            'boxes': boxes_t,\n            'labels': labels_t,\n            'label_num_positives': num_pos,\n            'box_num_positives':   num_pos,\n        }\n        return img_t, target\n\n# 3. Augmentations\ntrain_aug = A.Compose(\n    [\n        A.Resize(IMG_SIZE, IMG_SIZE),\n        A.RandomBrightnessContrast(p=0.5),\n        A.HorizontalFlip(p=0.5),\n        #A.RandomRotate90(p=0.0),\n    ],\n    bbox_params=A.BboxParams(format='coco', label_fields=['category_id'])\n)\nval_aug = A.Compose(\n    [A.Resize(IMG_SIZE, IMG_SIZE)],\n    bbox_params=A.BboxParams(format='coco', label_fields=['category_id'])\n)\n\n# 4. DataSet\ndataset_root = '/kaggle/input/0713-hackathon/dataset'\ntrain_ds = TrafficDataset(dataset_root, 'train', transforms=train_aug)\nval_ds   = TrafficDataset(dataset_root, 'val',   transforms=val_aug)\nprint(f\"Train images: {len(train_ds)}, Val images: {len(val_ds)}\")\n\n# 5. 类别计数（来自 Cell 2）\n# counts = {0:123, 1:71, 2:640, 3:159, 4:141, 5:266, 6:127, 7:3169, 8:1610}\n\n# 6. 采样权重\nimage_weights, default_weight = [], 1.0\nfor lp in train_ds.label_paths:\n    with open(lp) as f:\n        lines = [l for l in f.read().splitlines() if l.strip()]\n    if not lines:\n        image_weights.append(default_weight)\n    else:\n        cls_list = [int(l.split()[0]) for l in lines]\n        avg_cnt  = np.mean([counts[c] for c in cls_list])\n        image_weights.append(1.0 / (np.sqrt(avg_cnt) + 1e-6))\n\nassert len(image_weights) == len(train_ds)\n\n# 7. 自定义 collate_fn：图像 stack，targets 保持列表\ndef collate_fn(batch):\n    imgs, targets = list(zip(*batch))   # imgs: tuple(Tensor)  targets: tuple(dict)\n    imgs = torch.stack(imgs, 0)         # B,3,H,W\n    return imgs, list(targets)          # targets ⇒ list(dict)  不再做其他事\n\n# 8. DataLoader\nsampler = WeightedRandomSampler(image_weights, len(image_weights), replacement=True)\ntrain_loader = DataLoader(train_ds, batch_size=1, sampler=sampler,\n                          collate_fn=collate_fn, num_workers=4)\nval_loader   = DataLoader(val_ds, batch_size=1, shuffle=False,\n                          collate_fn=collate_fn, num_workers=4)\n\nprint(\"train_loader batches:\", len(train_loader), \"val_loader batches:\", len(val_loader))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-12T15:40:05.429772Z","iopub.execute_input":"2025-07-12T15:40:05.430056Z","iopub.status.idle":"2025-07-12T15:40:05.780585Z","shell.execute_reply.started":"2025-07-12T15:40:05.430037Z","shell.execute_reply":"2025-07-12T15:40:05.779591Z"}},"outputs":[{"name":"stdout","text":"Train images: 564, Val images: 72\ntrain_loader batches: 564 val_loader batches: 72\n","output_type":"stream"}],"execution_count":113},{"cell_type":"code","source":"# Cell 4 ▸ EfficientDet-D4 + Optimizer + Scheduler （最终版）\nimport math, torch\nfrom effdet import create_model, DetBenchTrain, get_efficientdet_config\n\n# 1⃣ 配置\ncfg = get_efficientdet_config('tf_efficientdet_d4')\ncfg.num_classes = 9                    # 9 类\n\n# 2⃣ 基础网络\nbase = create_model(cfg, bench_task='train', pretrained=True)\n\n# 3⃣ DetBenchTrain（关键：create_labeler=True ）\nmodel = DetBenchTrain(\n    base, cfg,\n    create_labeler=True          # ✅ 强制创建 anchor_labeler\n).cuda()                         # 单 GPU，显存最稳\n\n# ── 如果显存允许再并行，否则保持单卡 ──\n# model = torch.nn.DataParallel(model)\n\n# 4⃣ 优化器\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n\n# 5⃣ Scheduler：1 epoch Warm-up ➜ Cosine\nmax_epochs = 20\ndef warmup_cosine(ep):\n    return (ep + 1) if ep < 1 else 0.5 * (1 + math.cos(math.pi * (ep - 1) / (max_epochs - 1)))\nscheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=warmup_cosine)\n\n# 6⃣ AMP Scaler\nscaler = torch.cuda.amp.GradScaler()\n\nprint(\"✅ EfficientDet-D4 Bench (labeler on) — 单 GPU, AMP ready\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-12T15:40:05.781621Z","iopub.execute_input":"2025-07-12T15:40:05.781890Z","iopub.status.idle":"2025-07-12T15:40:05.830802Z","shell.execute_reply.started":"2025-07-12T15:40:05.781860Z","shell.execute_reply":"2025-07-12T15:40:05.829731Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_211/4000437396.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# 2⃣ 基础网络\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mbase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbench_task\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# 3⃣ DetBenchTrain（关键：create_labeler=True ）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/effdet/factory.py\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(model_name, bench_task, num_classes, pretrained, checkpoint_path, checkpoint_ema, **kwargs)\u001b[0m\n\u001b[1;32m      9\u001b[0m         checkpoint_path='', checkpoint_ema=False, **kwargs):\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_efficientdet_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     return create_model_from_config(\n\u001b[1;32m     13\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbench_task\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbench_task\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/effdet/config/model_config.py\u001b[0m in \u001b[0;36mget_efficientdet_config\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m    733\u001b[0m     \u001b[0;34m\"\"\"Get the default config for EfficientDet based on model name.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_detection_model_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m     \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mefficientdet_model_param_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m     \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_levels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_level\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_level\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may be unnecessary, ensure no references to param dict values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: {'name': 'tf_efficientdet_d4', 'backbone_name': 'tf_efficientnet_b4', 'backbone_args': {'drop_path_rate': 0.2}, 'backbone_indices': None, 'image_size': [1024, 1024], 'num_classes': 9, 'min_level': 3, 'max_level': 7, 'num_levels': 5, 'num_scales': 3, 'aspect_ratios': [[1.0, 1.0], [1.4, 0.7], [0.7, 1.4]], 'anchor_scale': 4.0, 'pad_type': 'same', 'act_type': 'swish', 'norm_layer': None, 'norm_kwargs': {'eps': 0.001, 'momentum': 0.01}, 'box_class_repeats': 4, 'fpn_cell_repeats': 7, 'fpn_channels': 224, 'separable_conv': True, 'apply_resample_bn': True, 'conv_bn_relu_pattern': False, 'downsample_type': 'max', 'upsample_type': 'nearest', 'redundant_bias': True, 'head_bn_level_first': False, 'head_act_type': None, 'fpn_name': None, 'fpn_config': None, 'fpn_drop_path_rate': 0.0, 'alpha': 0.25, 'gamma': 1.5, 'label_smoothing': 0.0, 'legacy_focal': False, 'jit_loss': False, 'delta': 0.1, 'box_loss_weight': 50.0, 'soft_nms': False, 'max_detection_points': 5000, 'max_det_per_image': 100, 'url': 'https://github.com/rwightman/efficientdet-pytorch/releases/download/v0.1/tf_efficientdet_d4_49-f56376d9.pth'}"],"ename":"KeyError","evalue":"{'name': 'tf_efficientdet_d4', 'backbone_name': 'tf_efficientnet_b4', 'backbone_args': {'drop_path_rate': 0.2}, 'backbone_indices': None, 'image_size': [1024, 1024], 'num_classes': 9, 'min_level': 3, 'max_level': 7, 'num_levels': 5, 'num_scales': 3, 'aspect_ratios': [[1.0, 1.0], [1.4, 0.7], [0.7, 1.4]], 'anchor_scale': 4.0, 'pad_type': 'same', 'act_type': 'swish', 'norm_layer': None, 'norm_kwargs': {'eps': 0.001, 'momentum': 0.01}, 'box_class_repeats': 4, 'fpn_cell_repeats': 7, 'fpn_channels': 224, 'separable_conv': True, 'apply_resample_bn': True, 'conv_bn_relu_pattern': False, 'downsample_type': 'max', 'upsample_type': 'nearest', 'redundant_bias': True, 'head_bn_level_first': False, 'head_act_type': None, 'fpn_name': None, 'fpn_config': None, 'fpn_drop_path_rate': 0.0, 'alpha': 0.25, 'gamma': 1.5, 'label_smoothing': 0.0, 'legacy_focal': False, 'jit_loss': False, 'delta': 0.1, 'box_loss_weight': 50.0, 'soft_nms': False, 'max_detection_points': 5000, 'max_det_per_image': 100, 'url': 'https://github.com/rwightman/efficientdet-pytorch/releases/download/v0.1/tf_efficientdet_d4_49-f56376d9.pth'}","output_type":"error"}],"execution_count":114},{"cell_type":"code","source":"# Cell 5 — 训练 + 验证（单 GPU, AMP, 累积梯度, 混淆矩阵）\n\nfrom torchvision.ops import box_iou\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom effdet import DetBenchPredict\n\n# ---------- 评估函数 -------------------------------------------------------\ndef evaluate(model, loader, iou_thr=0.5):\n    model.eval()\n    pred_head = DetBenchPredict(model)             # 单 GPU 直接用本体\n\n    y_true, y_pred = [], []\n    with torch.no_grad():\n        for imgs, targets in loader:               # imgs: (B,3,H,W)\n            imgs = imgs.cuda(non_blocking=True)\n            out  = pred_head(imgs)                 # tuple (boxes, scores, classes)\n\n            for bi, (boxes, scores, classes) in enumerate(zip(*out)):\n                gt_lbl, gt_box = targets[bi]['labels'], targets[bi]['boxes']\n                if gt_lbl.numel() == 0:\n                    continue\n                # IoU 匹配\n                ious = box_iou(boxes.cpu(), gt_box.cpu())\n                matches = torch.max(ious, dim=0)\n                for gi, (mx_iou, idx) in enumerate(zip(matches[0], matches[1])):\n                    if mx_iou >= iou_thr:\n                        y_true.append(gt_lbl[gi].item())\n                        y_pred.append(classes[idx].cpu().item())\n\n    cm = confusion_matrix(y_true, y_pred, labels=list(range(9)))\n    return cm\n\n# ---------- 训练主循环 -----------------------------------------------------\nmax_epochs   = 20\nbatch_size   = 1        # 与 DataLoader 一致\naccum_iter   = 4        # 累积 4 步等效 batch =4\nbest_f1, bad = 0, 0\n\nstep = 0\nfor epoch in range(max_epochs):\n    model.train()\n    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{max_epochs}\")\n    for imgs, targets in pbar:\n        # 搬到 GPU\n        imgs = imgs.cuda(non_blocking=True)\n        targets = [\n            {k: (v.cuda(non_blocking=True) if torch.is_tensor(v) else v)\n             for k, v in t.items()}\n            for t in targets\n        ]\n\n        with torch.cuda.amp.autocast():\n            loss, _, _ = model(imgs, targets)\n            loss = loss / accum_iter            # ① 累积梯度\n\n        scaler.scale(loss).backward()\n\n        # ② 每 accum_iter 步更新一次\n        if (step + 1) % accum_iter == 0:\n            scaler.step(optimizer)\n            scaler.update()\n            optimizer.zero_grad()\n\n        pbar.set_postfix(loss=float(loss) * accum_iter,   # 还原显示真实 loss\n                         lr=optimizer.param_groups[0]['lr'])\n        step += 1\n    scheduler.step()\n\n    # ---------- 验证 ----------\n    cm = evaluate(model, val_loader)\n    disp = ConfusionMatrixDisplay(cm, display_labels=list(range(9)))\n    disp.plot(include_values=False, cmap='Blues', xticks_rotation='vertical')\n    plt.title(f'Confusion Matrix Epoch {epoch+1}')\n    plt.show()\n\n    # ---------- Macro-F1 ----------\n    precision = np.diag(cm) / (cm.sum(axis=0) + 1e-9)\n    recall    = np.diag(cm) / (cm.sum(axis=1) + 1e-9)\n    f1_vals   = 2 * precision * recall / (precision + recall + 1e-9)\n    f1        = np.mean(f1_vals)\n    print(f\"Epoch {epoch+1}:  macro-F1 = {f1:.4f}\")\n\n    # ---------- Early-stop & Checkpoint ----------\n    if f1 > best_f1:\n        best_f1, bad = f1, 0\n        torch.save(model.state_dict(), 'best_d4.pth')\n    else:\n        bad += 1\n        if bad >= 5:\n            print(\"Early stopping ⏹️\")\n            break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-12T15:40:05.831412Z","iopub.status.idle":"2025-07-12T15:40:05.831683Z","shell.execute_reply.started":"2025-07-12T15:40:05.831522Z","shell.execute_reply":"2025-07-12T15:40:05.831530Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 6: 最佳模型加载 & Test 推理 + 生成 submission\nmodel.load_state_dict(torch.load('best_d4.pth'))\npredictor = DetBenchPredict(model.module)\n\ntest_imgs = sorted(glob.glob('/kaggle/input/**/test/images/*.jpg', recursive=True))\nresults = []\nfor img_path in tqdm(test_imgs, desc=\"Test Inference\"):\n    img = torch.tensor(plt.imread(img_path)).permute(2,0,1).float()/255.\n    boxes, scores, classes = predictor([img.cuda()])\n    # 按类计数\n    cnts = [0]*9\n    for c in classes.cpu(): cnts[c] += 1\n    results.append([os.path.basename(img_path), ';'.join(map(str,cnts))])\n\n# 写 CSV\nimport csv\nwith open('submission.csv','w', newline='') as f:\n    w=csv.writer(f); w.writerow(['pic_name','results'])\n    w.writerows(results)\nprint(\"Saved submission.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-12T15:40:05.833363Z","iopub.status.idle":"2025-07-12T15:40:05.833709Z","shell.execute_reply.started":"2025-07-12T15:40:05.833521Z","shell.execute_reply":"2025-07-12T15:40:05.833534Z"}},"outputs":[],"execution_count":null}]}